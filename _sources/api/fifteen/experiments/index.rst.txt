:mod:`fifteen.experiments`
==========================

.. py:module:: fifteen.experiments


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   fifteen.experiments.Experiment
   fifteen.experiments.TensorboardLogData




.. class:: Experiment

   We define an "experiment" as a simple directory, where files associated with some
   run of a training script are co-located.

   There's very little real code here; instead we use a common experiment data
   directory to implement thin wrappers around:


   * ``flax.training.checkpoints`` for checkpointing.
   * ``PyYAML`` and ``dcargs`` for serializing metadata.
   * ``tensorboardX.SummaryWriter`` for logging.

   .. attribute:: data_dir
      :annotation: :pathlib.Path

      

   .. attribute:: verbose
      :annotation: :bool = True

      

   .. method:: write_metadata(self, name: str, object: Any) -> None

      Serialize an object as a yaml file, then save it to the experiment's metadata
      directory. Includes special handling for dataclasses (via dcargs).


   .. method:: read_metadata(self, name: str, expected_type: Type[T]) -> T

      Load an object from the experiment's metadata directory. Includes special
      handling for dataclasses (via dcargs).


   .. method:: save_checkpoint(self, target: Pytree, step: int, prefix: str = 'checkpoint_', keep: int = 1, overwrite: bool = False, keep_every_n_steps: Optional[int] = None) -> str

      Thin wrapper around flax's ``save_checkpoint()`` function.
      Returns a file name, as a string.


   .. method:: restore_checkpoint(self, target: PytreeType, step: Optional[int] = None, prefix: str = 'checkpoint_') -> PytreeType

      Thin wrapper around flax's ``restore_checkpoint()`` function.


   .. method:: summary_writer(self) -> tensorboardX.SummaryWriter
      :property:

      Property for accessing a summary writer for Tensorboard logging.


   .. method:: log(self, log_data: fifteen.experiments.TensorboardLogData, step: int, log_scalars_every_n: int = 1, log_histograms_every_n: int = 1)

      Logging helper for Tensorboard.

      For TensorboardLogData instances returned from ``pmap``\ -transformed functions, see
      ``TensorboardLogData.fix_sharded_scalars()``.


   .. method:: assert_new(self) -> Experiment

      Makes sure that there are no existing checkpoints, logs, or metadata. Returns
      self.


   .. method:: assert_exists(self) -> Experiment

      Makes sure that there are existing checkpoints, logs, or metadata. Returns
      self.


   .. method:: clear(self) -> Experiment

      Deletes ``self.data_dir``. This clears all checkpoints, logs, and metadata
      inside of it. Returns self.


   .. method:: move(self, new_data_dir: pathlib.Path) -> Experiment

      Move all files corresponding to an experiment to a new location. Returns
      updated Experiment object.



.. class:: TensorboardLogData

   Data structure for logging to Tensorboard.

   .. attribute:: scalars
      :annotation: :Dict[str, Scalar]

      

   .. attribute:: histograms
      :annotation: :Dict[str, Array]

      

   .. method:: prefix(self, prefix: str) -> TensorboardLogData

      Add a prefix to all contained tag names. Useful for scoping, or creating
      those folders in the Tensorboard scalar view.


   .. method:: merge(self, other: TensorboardLogData) -> TensorboardLogData

      Merge two log data structures.


   .. method:: merge_scalars(self, scalars: Dict[str, Scalar] = {}) -> TensorboardLogData


   .. method:: merge_histograms(self, histograms: Dict[str, Array] = {}) -> TensorboardLogData


   .. method:: fix_sharded_scalars(self) -> TensorboardLogData

      When log data is returned from a function transformed by ``pmap``\ , scalars will
      often be returned as sharded arrays, distributed across multiple devices. This
      makes them no longer scalars, and breaks compatibility with standard logging
      utilities.

      To fix this, we replace each sharded array in the scalar dictionary with the
      first value from the flattened representation. Histogram data is unmodified.

      In the future, this might also support averaging across the scalars, but since
      an arithmetic mean doesn't make sense for many metrics the current approach is
      to simply call ``jax.lax.pmean`` in the pmapped function. Some performance
      analysis could be done here.



